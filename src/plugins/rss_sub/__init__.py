import json
import os
import asyncio
import feedparser
from nonebot import on_command, require, get_bot
from nonebot.adapters import Message
from nonebot.adapters.onebot.v11 import GroupMessageEvent, PrivateMessageEvent
from nonebot.params import CommandArg
from nonebot.log import logger
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from typing import Union

from nonebot import get_driver

# Initialize Scheduler
scheduler = AsyncIOScheduler()
driver = get_driver()

@driver.on_startup
async def start_scheduler():
    if not scheduler.running:
        scheduler.start()

# File to store subscriptions
SUBS_FILE = "data/rss_subs.json"  # Store in data directory for persistence

def load_subs():
    if not os.path.exists(SUBS_FILE):
        return {}
    with open(SUBS_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_subs(subs):
    with open(SUBS_FILE, "w", encoding="utf-8") as f:
        json.dump(subs, f, indent=4, ensure_ascii=False)

# Commands
add_rss = on_command("add_rss", aliases={"è®¢é˜…"}, priority=5)

@add_rss.handle()
async def handle_add_rss(event: Union[GroupMessageEvent, PrivateMessageEvent], args: Message = CommandArg()):
    url = args.extract_plain_text().strip()
    if not url:
        await add_rss.finish("è¯·è¾“å…¥ RSS é“¾æ¥ã€‚")
        return

    subs = load_subs()
    
    # Determine subscriber info
    subscriber = {}
    if isinstance(event, GroupMessageEvent):
        subscriber = {"type": "group", "id": event.group_id}
    elif isinstance(event, PrivateMessageEvent):
        subscriber = {"type": "private", "id": event.user_id}
    
    # Check if feed exists
    if url not in subs:
        # New feed
        feed = feedparser.parse(url)
        if feed.bozo:
            await add_rss.finish("æ— æ•ˆçš„ RSS æºã€‚")
            return
        
        title = feed.feed.get("title", "Unknown Feed")
        
        # Initialize last_entry_id with the most recent entry to avoid pushing all history
        latest_entry_id = None
        if feed.entries:
            latest_entry_id = feed.entries[0].get("id", feed.entries[0].get("link"))
        
        subs[url] = {
            "title": title,
            "last_entry_id": latest_entry_id,  # Set to latest entry, not None
            "subscribers": [subscriber]
        }
        msg = f"æˆåŠŸè®¢é˜… {title}ï¼å·²å¿½ç•¥å†å²æ¶ˆæ¯ï¼Œä»…æ¨é€æ–°å†…å®¹ã€‚"
    else:
        # Existing feed, check if already subscribed
        if subscriber in subs[url]["subscribers"]:
            await add_rss.finish("ä½ å·²ç»è®¢é˜…è¿‡è¿™ä¸ªæºäº†ã€‚")
            return
        
        subs[url]["subscribers"].append(subscriber)
        msg = f"æˆåŠŸè®¢é˜… {subs[url]['title']}ï¼"

    save_subs(subs)
    await add_rss.finish(msg)

# Scheduled Task
async def check_rss():
    logger.info("Checking RSS feeds...")
    subs = load_subs()
    bot = get_bot()
    
    for url, data in subs.items():
        try:
            feed = feedparser.parse(url)
            if not feed.entries:
                continue
            
            new_entries = []
            last_id = data.get("last_entry_id")
            
            # Collect all new entries (up to 20 to avoid excessive processing)
            for entry in feed.entries:
                entry_id = entry.get("id", entry.get("link"))
                if entry_id == last_id:
                    break
                new_entries.append(entry)
                
                # Hard limit: max 20 entries to analyze
                if len(new_entries) >= 20:
                    logger.info(f"RSS {data['title']}: è¾¾åˆ°æ”¶é›†ä¸Šé™(20æ¡)")
                    break
            
            if new_entries:
                # Update last_id
                data["last_entry_id"] = new_entries[0].get("id", new_entries[0].get("link"))
                save_subs(subs)
                
                # Smart filtering: if more than 5 entries, use AI to select top 5 by importance
                entries_to_push = new_entries
                if len(new_entries) > 5:
                    logger.info(f"RSS {data['title']}: æ£€æµ‹åˆ°{len(new_entries)}æ¡æ–°å†…å®¹ï¼Œä½¿ç”¨AIç­›é€‰...")
                    entries_to_push = await select_top_entries(new_entries, data['title'])
                
                # Build a single message with all entries from this source
                entry_count = len(entries_to_push)
                msg_lines = [f"ğŸ“¢ {data['title']} æ›´æ–° ({entry_count}æ¡)ï¼š\n"]
                
                for idx, entry in enumerate(reversed(entries_to_push), 1):
                    msg_lines.append(f"{idx}. {entry.title}")
                    msg_lines.append(f"   {entry.link}")
                    if idx < entry_count:  # Add separator between entries
                        msg_lines.append("")
                
                msg = "\n".join(msg_lines)
                
                # Push the combined message to all subscribers
                subscribers = data.get("subscribers", [])
                for sub in subscribers:
                    try:
                        # Check length for smart forwarding
                        threshold = int(os.getenv("FORWARD_THRESHOLD", "100"))
                        
                        if len(msg) > threshold:
                            from src.utils.message_forwarder import send_group_forward_message, send_private_forward_message, split_text_into_paragraphs
                            paragraphs = split_text_into_paragraphs(msg)
                            
                            if sub["type"] == "group":
                                await send_group_forward_message(bot, int(sub["id"]), paragraphs)
                            elif sub["type"] == "private":
                                await send_private_forward_message(bot, int(sub["id"]), paragraphs)
                        else:
                            if sub["type"] == "group":
                                await bot.send_group_msg(group_id=int(sub["id"]), message=msg)
                            elif sub["type"] == "private":
                                await bot.send_private_msg(user_id=int(sub["id"]), message=msg)
                    except Exception as e:
                        logger.error(f"Failed to send RSS to {sub}: {e}")
                        
                logger.info(f"Pushed {entry_count} RSS items from {data['title']}")
                    
        except Exception as e:
            logger.error(f"Error checking RSS {url}: {e}")

async def select_top_entries(entries, feed_title):
    """
    Use AI to select the top 5 most important/newsworthy entries from a list.
    Falls back to latest 5 if AI fails.
    """
    try:
        from src.utils.openai_client import openai_client
        
        # Build prompt with all entry titles
        entries_text = "\n".join([
            f"{idx+1}. {entry.title}" 
            for idx, entry in enumerate(entries)
        ])
        
        prompt = (
            f"ä½ æ˜¯æ–°é—»ç¼–è¾‘ã€‚ä»¥ä¸‹æ˜¯{feed_title}çš„{len(entries)}æ¡æ–°é—»æ ‡é¢˜ã€‚\n"
            f"è¯·é€‰å‡ºæœ€é‡è¦ã€æœ€æœ‰æ–°é—»ä»·å€¼çš„5æ¡ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ã€‚\n"
            f"åªéœ€è¿”å›é€‰ä¸­çš„æ–°é—»åºå·ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼š3,7,1,12,5\n\n"
            f"{entries_text}"
        )
        
        # Use Pro model for highest quality filtering
        response = await openai_client.generate_content(
            'auto', 
            prompt, 
            task_type='summary',
            auto_select=False
        )
        
        # Parse AI response to get selected indices
        selected_indices = []
        for num in response.strip().split(','):
            try:
                idx = int(num.strip()) - 1  # Convert to 0-indexed
                if 0 <= idx < len(entries):
                    selected_indices.append(idx)
            except ValueError:
                continue
        
        # If AI successfully selected entries, return them
        if selected_indices:
            selected = [entries[i] for i in selected_indices[:5]]
            logger.info(f"AIç­›é€‰æˆåŠŸï¼šä»{len(entries)}æ¡ä¸­é€‰å‡º{len(selected)}æ¡")
            return selected
        else:
            logger.warning(f"AIè¿”å›çš„ç´¢å¼•æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
        
    except ValueError as e:
        # Handle openai_client specific errors (finish_reason issues)
        logger.warning(f"AIç­›é€‰å¤±è´¥ (å†…å®¹é—®é¢˜): {e}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
    except Exception as e:
        # Handle all other unexpected errors
        logger.warning(f"AIç­›é€‰å¤±è´¥ ({type(e).__name__}): {e}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
    
    # Fallback: return latest 5
    logger.info(f"ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼šé€‰æ‹©æœ€æ–°çš„5æ¡")
    return entries[:5]

# Schedule the check every 90 minutes (low-frequency mode)
scheduler.add_job(check_rss, "interval", minutes=90)

# RSS Digest Feature
rss_digest = on_command("rss_digest", aliases={"ä»Šæ—¥æ‘˜è¦", "RSSæ‘˜è¦"}, priority=5)

@rss_digest.handle()
async def handle_rss_digest(event: Union[GroupMessageEvent, PrivateMessageEvent], args: Message = CommandArg()):
    # /rss_digest HH:MM (Set daily digest time)
    # For now, let's just trigger it immediately for testing if no time provided, 
    # or save the schedule if time provided.
    
    args_text = args.extract_plain_text().strip()
    
    # Determine subscriber info
    target_id = str(event.user_id) if isinstance(event, PrivateMessageEvent) else str(event.group_id)
    target_type = "private" if isinstance(event, PrivateMessageEvent) else "group"
    
    subs = load_subs()
    
    # Collect recent entries from subscribed feeds
    recent_entries = []
    subscriber_signature = {"type": target_type, "id": int(target_id)}
    
    for url, data in subs.items():
        if subscriber_signature in data.get("subscribers", []):
            # Fetch feed again to get latest content (or use cached if we had it, but we don't cache content)
            # This might be slow if many feeds.
            try:
                feed = feedparser.parse(url)
                # Get entries from last 24h (simplified: just take top 5 from each feed for now)
                for entry in feed.entries[:5]:
                    recent_entries.append(f"- [{data['title']}] {entry.title}: {entry.link}")
            except Exception:
                pass
    
    if not recent_entries:
        await rss_digest.finish("æš‚æ— è®¢é˜…æˆ–æ— è¿‘æœŸæ›´æ–°ã€‚")
        return

    await rss_digest.send("æ­£åœ¨ç”Ÿæˆä»Šæ—¥æ‘˜è¦ï¼Œè¯·ç¨å€™...")
    
    # Limit to top 20 items to avoid token limits (reduced from 50)
    content_text = "\n".join(recent_entries[:20])
    
    prompt = (
        "ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ç”¨æˆ· RSS è®¢é˜…çš„è¿‘æœŸæ–‡ç« åˆ—è¡¨ã€‚"
        "è¯·æŒ‘é€‰å‡ºæœ€é‡è¦çš„ 5 ç¯‡æ–‡ç« ã€‚"
        "å¯¹äºæ¯ä¸€ç¯‡ï¼Œæä¾›æ ‡é¢˜ã€ä¸€å¥è¯çš„ä¸­æ–‡é‡è¦æ€§æ€»ç»“ï¼Œä»¥åŠé“¾æ¥ã€‚"
        "è¯·ä½¿ç”¨å¸¦ç¼–å·çš„åˆ—è¡¨æ ¼å¼è¾“å‡ºã€‚\n\n"
        f"{content_text}"
    )
    
    
    from src.utils.openai_client import openai_client
    from src.utils.text_formatter import markdown_to_plain_text
    
    # Variables to store results
    digest = None
    error_message = None
    
    try:
        digest = await openai_client.generate_content('auto', prompt, task_type='summary')
        # Convert Markdown to plain text for QQ compatibility
        digest = markdown_to_plain_text(digest)
    except ValueError as e:
        # Handle specific errors from openai_client
        error_msg = str(e)
        if "å®‰å…¨è¿‡æ»¤å™¨" in error_msg or "SAFETY" in error_msg:
            error_message = "âš ï¸ ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼šRSSå†…å®¹åŒ…å«æ•æ„Ÿä¿¡æ¯è¢«è¿‡æ»¤\nå»ºè®®ï¼šè¯·æ£€æŸ¥è®¢é˜…æºå†…å®¹"
        elif "token" in error_msg.lower() or "MAX_TOKENS" in error_msg:
            error_message = "âš ï¸ ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼šå†…å®¹è¿‡é•¿\nå»ºè®®ï¼šå‡å°‘è®¢é˜…æºæ•°é‡æˆ–ç¨åé‡è¯•"
        elif "ç©ºå“åº”" in error_msg:
            error_message = "âš ï¸ ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼šAPIè¿”å›ç©ºå“åº”\nå»ºè®®ï¼šè¯·ç¨åé‡è¯•"
        else:
            error_message = f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼š{error_msg}"
    except Exception as e:
        # Handle unexpected errors
        error_message = f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼š{type(e).__name__}: {str(e)}\nå»ºè®®ï¼šè¯·æ£€æŸ¥æ—¥å¿—æˆ–ç¨åé‡è¯•"
    
    # Now send the response (outside of the try-except to avoid catching FinishedException)
    # Now send the response (outside of the try-except to avoid catching FinishedException)
    if digest:
        msg = f"ğŸ“° ä»Šæ—¥ RSS æ‘˜è¦ï¼š\n{digest}"
        
        # Use smart forwarding
        from src.utils.message_forwarder import send_message_smart
        threshold = int(os.getenv("FORWARD_THRESHOLD", "100"))
        
        try:
            bot = get_bot()
            await send_message_smart(bot, msg, event, threshold)
        except Exception as e:
            logger.error(f"Smart send failed: {e}")
            await rss_digest.send(msg)
            
        await rss_digest.finish()
    else:
        await rss_digest.finish(error_message)


# RSS List Command
rss_list = on_command("rss", aliases={"è®¢é˜…åˆ—è¡¨"}, priority=5)
rss_delete = on_command("å–æ¶ˆè®¢é˜…", priority=5)
rss_show_list = on_command("è®¢é˜…åˆ—è¡¨", priority=5)

async def perform_list(matcher, event):
    """
    æ‰§è¡Œæ˜¾ç¤ºè®¢é˜…åˆ—è¡¨é€»è¾‘
    """
    # Determine subscriber info
    target_id = str(event.user_id) if isinstance(event, PrivateMessageEvent) else str(event.group_id)
    target_type = "private" if isinstance(event, PrivateMessageEvent) else "group"
    subscriber_signature = {"type": target_type, "id": int(target_id)}
    
    subs = load_subs()
    
    # Filter subs for this user/group
    user_subs = []
    for url, data in subs.items():
        if subscriber_signature in data.get("subscribers", []):
            user_subs.append((url, data["title"]))
    
    if not user_subs:
        await matcher.finish("å½“å‰æš‚æ— è®¢é˜…ã€‚")
        return
        
    msg = "ğŸ“‹ å·²è®¢é˜…åˆ—è¡¨ï¼š\n"
    for idx, (url, title) in enumerate(user_subs):
        msg += f"{idx + 1}. {title}\n   {url}\n"
        
    # Use smart forwarding
    from src.utils.message_forwarder import send_message_smart
    threshold = int(os.getenv("FORWARD_THRESHOLD", "100"))
    
    try:
        bot = get_bot()
        await send_message_smart(bot, msg, event, threshold)
    except Exception:
        await matcher.send(msg)
        
    await matcher.finish()

async def perform_unsubscribe(matcher, event, target):
    """
    æ‰§è¡Œå–æ¶ˆè®¢é˜…é€»è¾‘
    """
    # Determine subscriber info
    target_id = str(event.user_id) if isinstance(event, PrivateMessageEvent) else str(event.group_id)
    target_type = "private" if isinstance(event, PrivateMessageEvent) else "group"
    subscriber_signature = {"type": target_type, "id": int(target_id)}
    
    subs = load_subs()
    
    # Filter subs for this user/group
    user_subs = []
    for url, data in subs.items():
        if subscriber_signature in data.get("subscribers", []):
            user_subs.append((url, data["title"]))
    
    url_to_remove = None
    
    # Try to parse as index
    if target.isdigit():
        idx = int(target) - 1
        if 0 <= idx < len(user_subs):
            url_to_remove = user_subs[idx][0]
    else:
        # Try to match URL
        if target in subs:
            url_to_remove = target
    
    if not url_to_remove:
        await matcher.finish("æœªæ‰¾åˆ°è¯¥è®¢é˜…ã€‚")
        return
        
    # Remove subscriber
    subs[url_to_remove]["subscribers"].remove(subscriber_signature)
    
    # If no subscribers left, remove feed? 
    if not subs[url_to_remove]["subscribers"]:
        del subs[url_to_remove]
        
    save_subs(subs)
    await matcher.finish(f"æˆåŠŸå–æ¶ˆè®¢é˜… {url_to_remove}ã€‚")


@rss_delete.handle()
async def handle_rss_delete(event: Union[GroupMessageEvent, PrivateMessageEvent], args: Message = CommandArg()):
    target = args.extract_plain_text().strip()
    if not target:
        await rss_delete.finish("ç”¨æ³•ï¼š/å–æ¶ˆè®¢é˜… <é“¾æ¥æˆ–åºå·>")
        return
    
    await perform_unsubscribe(rss_delete, event, target)


@rss_show_list.handle()
async def handle_rss_show_list(event: Union[GroupMessageEvent, PrivateMessageEvent]):
    await perform_list(rss_show_list, event)


@rss_list.handle()
async def handle_rss_list(event: Union[GroupMessageEvent, PrivateMessageEvent], args: Message = CommandArg()):
    # Usage: /rss list
    #        /rss del <url_or_index>
    
    args_text = args.extract_plain_text().strip().split()
    if not args_text:
        await rss_list.finish("ç”¨æ³•ï¼š/rss list æˆ– /rss del <é“¾æ¥æˆ–åºå·>")
        return
        
    action = args_text[0].lower()
    
    if action == "list":
        await perform_list(rss_list, event)
        
    elif action == "del":
        if len(args_text) < 2:
            await rss_list.finish("ç”¨æ³•ï¼š/rss del <é“¾æ¥æˆ–åºå·>")
            return
            
        target = args_text[1]
        await perform_unsubscribe(rss_list, event, target)
    
    else:
        await rss_list.finish("æœªçŸ¥æ“ä½œã€‚è¯·ä½¿ç”¨ list æˆ– delã€‚")
